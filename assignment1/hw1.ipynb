{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Word2Vec Implementation\n",
    "Task:\n",
    "- CBOW / Skip-gram using gensim\n",
    "- embedding dimensions 100,300,500\n",
    "- subset of wikipedia data -> perform preprocessing\n",
    "- evaluation using WordSim353 dataset, computer Spearman's correlation coefficient between embeddings and WordSim353 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my dataset taken from: https://www.kaggle.com/datasets/jjinho/wikipedia-20230701?resource=download&select=b.parquet\n",
    "articles starting with ab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "df = pd.read_parquet(r'C:\\Users\\matte\\Tsinghua\\SecondSemester\\NLP\\Assignments\\NLP_assignment_1\\b.parquet\\b.parquet')\n",
    "\n",
    "# elimnate stopwords, and lowercase\n",
    "stopwords = set(stopwords.words('english'))\n",
    "df = df['text'].apply(lambda x: ' '.join([word.lower() for word in word_tokenize(x) if word.lower() not in stopwords]))\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\matte\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\matte\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'word':\n",
      "[-0.49217764 -1.6475337  -2.6037877   1.9936352   0.2410293  -2.884838\n",
      " -0.54240084 -0.2847878   3.8169143  -0.35356095 -0.32403955 -2.3672535\n",
      "  0.49424002 -0.82202256 -1.1617094   1.6686698   0.68227816 -2.3130293\n",
      "  3.1425831  -1.6599718  -1.1164575   1.8766254  -0.51606256  0.14188436\n",
      "  1.6705462   0.26702815 -4.636656    0.8631962   1.031978   -2.7034738\n",
      "  1.1326134   2.6448078  -1.5893145   1.6827046   0.27565143 -1.0085858\n",
      " -0.56139183  1.0290754  -0.96094507  0.6398163   2.3282611  -2.0165942\n",
      " -0.8735068   0.7642665  -1.5062762  -2.4455447  -3.587279    2.0453951\n",
      "  2.885207    1.4384016  -2.9046617  -0.13190281  1.784654    2.3659742\n",
      "  0.86444473  2.5305827   2.6790931   1.4854783   2.0200462   2.273612\n",
      "  0.5642112  -2.3650575   2.8583832   2.1108289  -0.8617417   0.93796104\n",
      "  2.931189   -0.691035    0.8769942  -0.586949   -3.638812    2.7810962\n",
      "  1.6093385  -1.549856   -0.6651917  -0.4263288   1.369236    0.18044865\n",
      "  1.9094195   1.4904673  -2.4179108  -0.68863237 -2.5238783   3.131539\n",
      "  0.8779671  -0.7307744   0.93316793  0.9978892   1.2600964  -0.53490716\n",
      "  0.37085056 -1.4366624  -0.7684391   2.1817467   0.07275863  0.72265446\n",
      "  0.63887227 -0.06606013  0.7745567   1.3400648 ]\n",
      "\n",
      "Words similar to 'word':\n",
      "phrase: 0.8568\n",
      "pronunciation: 0.8006\n",
      "suffix: 0.7842\n",
      "alphabet: 0.7838\n",
      "noun: 0.7797\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "# nltk resources\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('punkt_tab')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# 2. Training CBOW Model with gensim\n",
    "# ------------------------\n",
    "# In gensim's Word2Vec, the CBOW architecture is used by default (sg=0).\n",
    "# The negative parameter specifies the number of negative samples.\n",
    "model = Word2Vec(\n",
    "    sentences=tokenized_sentences,\n",
    "    vector_size=100,   # Dimensionality of the word vectors\n",
    "    window=5,          # Context window size\n",
    "    min_count=1,       # Minimum frequency to consider a word in the vocabulary\n",
    "    sg=0,              # Use CBOW (sg=1 would switch to Skip-gram)\n",
    "    negative=5,        # Number of negative samples (for negative sampling)\n",
    "    epochs=1          # Number of training epochs\n",
    ")\n",
    "# Save the model to a file\n",
    "model.save(\"cbow_model.model\")\n",
    "# ------------------------\n",
    "# 3. Inspecting the Learned Embeddings\n",
    "# ------------------------\n",
    "# For example, get the vector for a specific word:\n",
    "word = 'word'\n",
    "if word in model.wv:\n",
    "    vector = model.wv[word]\n",
    "    print(f\"Vector for '{word}':\")\n",
    "    print(vector)\n",
    "else:\n",
    "    print(f\"The word '{word}' is not in the vocabulary.\")\n",
    "\n",
    "# Optionally, find similar words\n",
    "similar_words = model.wv.most_similar(word, topn=5)\n",
    "print(f\"\\nWords similar to '{word}':\")\n",
    "for similar_word, similarity in similar_words:\n",
    "    print(f\"{similar_word}: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
